# -*- coding: utf-8 -*-
"""Sales Forecasting and Inventory Management.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13h1uj7u_4ShGwsMYoF5Ph_aTKScbL-9G
"""

import pandas as pd

# Load the dataset
data = pd.read_csv('features.csv')  # Adjust the path if needed

# Display the first few rows
print(data.head())

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from flask import Flask, request, jsonify

# Load the dataset
data = pd.read_csv('features.csv')  # Adjust the path if needed

# Convert 'Date' to datetime
data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')  # Correct format

# Check for missing values
print("Missing values in each column:\n", data.isnull().sum())

# Fill or drop missing values (for example, fill with the mean)
data.fillna(data.mean(), inplace=True)

# Encode the 'IsHoliday' column
data['IsHoliday'] = data['IsHoliday'].map({True: 1, False: 0})

# Feature selection
# Assuming you have a 'Sales' column to predict (this may need to be created if not in your dataset)
# Here, I'll create a synthetic 'Sales' column for demonstration
data['Sales'] = np.random.randint(50, 500, data.shape[0])  # Replace this line with your actual sales data if available

# Remove the 'Date' column from features
features = data[['Store', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',
                 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']]
target = data['Sales']  # Replace 'Sales' with your actual target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Model training
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Calculate the mean squared error
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

# Data Visualization (Optional)
plt.figure(figsize=(10, 6))
sns.lineplot(data=data, x='Date', y='Sales', label='Sales Over Time')
plt.title('Sales Over Time')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.xticks(rotation=45)
plt.legend()
plt.show()

# Flask App (Optional)
app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json(force=True)
    features = np.array(data['features']).reshape(1, -1)  # Adjust based on your input structure
    prediction = model.predict(features)
    return jsonify({'prediction': prediction[0]})

if __name__ == '__main__':
    app.run(debug=True)

from sklearn.metrics import mean_absolute_error, r2_score

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Absolute Error: {mae}')
print(f'R-squared: {r2}')

feature_importances = model.feature_importances_
feature_names = features.columns
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df)
plt.title('Feature Importance')
plt.show()

